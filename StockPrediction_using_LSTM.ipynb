{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKM4ACUByFl5ilmDoNLscW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BalaLearning/practical-python-for-algorithmic-trading-4403633/blob/main/StockPrediction_using_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1xLpyW5Q_zH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import datetime as dt\n",
        "from datetime import date\n",
        "import matplotlib.pyplot as plt\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "START = \"2015-01-01\"\n",
        "TODAY = date.today().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "# Define a function to load the dataset\n",
        "\n",
        "def load_data(ticker):\n",
        "    data = yf.download(ticker, START, TODAY)\n",
        "    data.reset_index(inplace=True)\n",
        "    return data\n",
        "\n",
        "    data = load_data('AAPL')\n",
        "    df=data\n",
        "    df.head()\n",
        "\n",
        "        # Inspect the columns of the DataFrame to identify the correct columns to drop\n",
        "    print(df.columns)\n",
        "\n",
        "    # Sort the columns (MultiIndex) to ensure correct dropping\n",
        "    df.sort_index(axis=1, inplace=True)\n",
        "    print(\"\\nColumns after sorting:\")\n",
        "    print(df.columns)\n",
        "\n",
        "    # Drop the 'Date' column from the MultiIndex\n",
        "    df.drop('Date', axis=1, inplace=True)\n",
        "\n",
        "    df.head()\n",
        "\n",
        "    plt.plot(df.Close)\n",
        "\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "    scaler = MinMaxScaler(feature_range=(0,1))\n",
        "    df = scaler.fit_transform(df)\n",
        "\n",
        "    # Splitting data into training and testing sets\n",
        "    training_size = int(len(df) * 0.65)\n",
        "    test_size = len(df) - training_size\n",
        "    train_data, test_data = df[0:training_size,:], df[training_size:len(df),:1]\n",
        "\n",
        "    # Function to create dataset for LSTM\n",
        "    def create_dataset(dataset, time_step=1):\n",
        "        dataX, dataY = [], []\n",
        "        for i in range(len(dataset)-time_step-1):\n",
        "            a = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2..,99   100\n",
        "            dataX.append(a)\n",
        "            dataY.append(dataset[i+time_step, 0])\n",
        "    return np.array(dataX), np.array(dataY)\n",
        "\n",
        "    # Reshape into X=t,t+1,t+2..t+99 and Y=t+100\n",
        "    time_step = 100\n",
        "    X_train, y_train = create_dataset(train_data, time_step)\n",
        "    X_test, y_test = create_dataset(test_data, time_step)\n",
        "\n",
        "    # Reshape input to be [samples, time steps, features]\n",
        "    X_train =X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
        "    X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
        "\n",
        "    # Create the LSTM model\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import Dense\n",
        "    from tensorflow.keras.layers import LSTM\n",
        "\n",
        "    model=Sequential()\n",
        "    model.add(LSTM(50,return_sequences=True,input_shape=(100,1)))\n",
        "    model.add(LSTM(50,return_sequences=True))\n",
        "    model.add(LSTM(50))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error',optimizer='adam')\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.fit(X_train,y_train,validation_split=0.1,epochs=60,batch_size=64,verbose=1)\n",
        "\n",
        "    # Make predictions\n",
        "    train_predict=model.predict(X_train)\n",
        "    test_predict=model.predict(X_test)\n",
        "\n",
        "    # Inverse transform the predictions\n",
        "    train_predict=scaler.inverse_transform(train_predict)\n",
        "    test_predict=scaler.inverse_transform(test_predict)\n",
        "\n",
        "    # Evaluate the model\n",
        "    import math\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "\n",
        "    math.sqrt(mean_squared_error(y_train,train_predict))\n",
        "\n",
        "    math.sqrt(mean_squared_error(y_test,test_predict))\n",
        "\n",
        "    # Plotting\n",
        "    # shift train predictions for plotting\n",
        "    look_back=100\n",
        "    trainPredictPlot = np.empty_like(df)\n",
        "    trainPredictPlot[:, :] = np.nan\n",
        "    trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
        "    # shift test predictions for plotting\n",
        "    testPredictPlot = np.empty_like(df)\n",
        "    testPredictPlot[:, :] = np.nan\n",
        "    testPredictPlot[len(train_predict)+(look_back*2)+1:len(df)-1, :] = test_predict\n",
        "    # plot baseline and predictions\n",
        "    plt.plot(scaler.inverse_transform(df))\n",
        "    plt.plot(trainPredictPlot)\n",
        "    plt.plot(testPredictPlot)\n",
        "    plt.show()"
      ]
    }
  ]
}